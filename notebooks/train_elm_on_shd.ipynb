{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c730d809-4b95-4fa4-945d-09103a1bbbbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: reduced implementation might require slightly different parameters for same results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182c286f-8a28-4500-a9ee-ec48956e6b0e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": "# Imports\nimport os\nimport random\nfrom pathlib import Path\n\nimport numpy as np\nimport torch\nfrom lightning.pytorch import Trainer\nfrom lightning.pytorch.callbacks import ModelCheckpoint, EarlyStopping"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf082d49-a561-456b-8dde-23614ad752c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": "# Import ELM components\nfrom elmneuron.expressive_leaky_memory_neuron_v2 import ELM\nfrom elmneuron.tasks.classification_task import ClassificationTask\nfrom elmneuron.shd.shd_datamodule import SHDDataModule\nfrom elmneuron.shd.shd_download_utils import get_shd_dataset\nfrom elmneuron.callbacks import (\n    SequenceVisualizationCallback,\n    MemoryDynamicsCallback,\n)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db9cf83-f768-4733-bbb2-37cbec34db27",
   "metadata": {},
   "outputs": [],
   "source": "# Seeding & Config\ngeneral_seed = 0\nos.environ['PYTHONHASHSEED'] = str(general_seed)\nrandom.seed(general_seed)\nnp.random.seed(general_seed)\ntorch.manual_seed(general_seed)\ntorch.cuda.manual_seed(general_seed)\ntorch.backends.cudnn.deterministic = True\n\n# Dataset config\ndataset_type = \"shd\"  # \"shd\" or \"shdadding\"\ndata_path = \"./shd_data\"\nbin_size = 10\nnum_classes = 20 if dataset_type == \"shd\" else 19\nnum_input_channel = 700\n\n# Model config\nlambda_value = 5.0\nnum_memory = 100\nmemory_tau_min = 1.0\nmemory_tau_max = 500.0\nlearn_memory_tau = False\ntau_b_value = float(bin_size)\n\n# Training config\nlearning_rate = 5e-3\nnum_epochs = 10\nbatch_size = 8\ndropout = 0.5"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1eda040f-79d8-4020-8a1f-6163c729cebe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available at: ./shd_data/shd_train.h5\n",
      "Available at: ./shd_data/shd_test.h5\n"
     ]
    }
   ],
   "source": [
    "# Data download config\n",
    "data_path = \"shd_data\"\n",
    "get_shd_dataset(\"./\", data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8de4b45-ed6d-4e80-a93d-ba37924ce29d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": "# Setup DataModule\ndatamodule = SHDDataModule(\n    data_dir=data_path,\n    dataset_type=dataset_type,\n    batch_size=batch_size,\n    bin_size=bin_size,\n    valid_fraction=0.2,\n    num_workers=4,\n    seed=general_seed,\n    dropout=dropout,\n)\n\n# Prepare data (download if needed)\ndatamodule.prepare_data()\ndatamodule.setup(\"fit\")\n\nprint(f\"Training samples: {len(datamodule.train_dataset)}\")\nprint(f\"Validation samples: {len(datamodule.val_dataset)}\")\nprint(f\"Input dimension: {datamodule.input_dim}\")\nprint(f\"Number of classes: {datamodule.num_classes}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1d2ed1-01a3-4cd1-9ac8-9393b7b920e7",
   "metadata": {},
   "outputs": [],
   "source": "# Create ELM model and Lightning task wrapper\n\n# Create base ELM model\nelm_model = ELM(\n    num_input=datamodule.input_dim,\n    num_output=datamodule.num_classes,\n    num_memory=num_memory,\n    lambda_value=lambda_value,\n    tau_b_value=tau_b_value,\n    memory_tau_min=memory_tau_min,\n    memory_tau_max=memory_tau_max,\n    learn_memory_tau=learn_memory_tau,\n    delta_t=bin_size,\n)\n\n# Wrap in Lightning classification task\nlightning_module = ClassificationTask(\n    model=elm_model,\n    learning_rate=learning_rate,\n    optimizer=\"adamax\",\n    scheduler=\"cosine\",\n    scheduler_kwargs={\"T_max\": num_epochs * len(datamodule.train_dataset) // batch_size},\n    output_selection=\"last\",  # Use last timestep for SHD classification\n)\n\nprint(f\"Model initialized with {sum(p.numel() for p in elm_model.parameters())} parameters\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91118916-690c-4f82-80e8-b2177fa164d8",
   "metadata": {},
   "outputs": [],
   "source": "# Setup Lightning Trainer\n\ncallbacks = [\n    # Model checkpointing\n    ModelCheckpoint(\n        dirpath=\"./checkpoints_shd\",\n        filename=\"elm-shd-{epoch:02d}-{val/accuracy:.4f}\",\n        monitor=\"val/accuracy\",\n        mode=\"max\",\n        save_top_k=3,\n        save_last=True,\n    ),\n    # Early stopping\n    EarlyStopping(\n        monitor=\"val/accuracy\",\n        patience=5,\n        mode=\"max\",\n        verbose=True,\n    ),\n    # Visualization callbacks\n    SequenceVisualizationCallback(\n        log_every_n_epochs=5,\n        num_samples=4,\n        task_type=\"classification\",\n        save_dir=\"./visualizations_shd\",\n        log_to_wandb=False,\n    ),\n    MemoryDynamicsCallback(\n        log_every_n_epochs=5,\n        num_samples=2,\n        save_dir=\"./memory_shd\",\n        log_to_wandb=False,\n    ),\n]\n\n# Create trainer\ntrainer = Trainer(\n    max_epochs=num_epochs,\n    accelerator=\"auto\",\n    devices=1,\n    callbacks=callbacks,\n    deterministic=True,\n    log_every_n_steps=50,\n    enable_progress_bar=True,\n)\n\n# Train the model\ntrainer.fit(lightning_module, datamodule=datamodule)\n\n# Test the model\ntrainer.test(lightning_module, datamodule=datamodule, ckpt_path=\"best\")\n\n# Save the best model\ntorch.save(lightning_module.model.state_dict(), \"./shd_best_model.pt\")\nprint(\"Model saved to ./shd_best_model.pt\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1ebff9-c1f4-4126-8ffc-39094a09f727",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
