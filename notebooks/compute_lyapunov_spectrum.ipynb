{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lyapunov Spectrum Computation for ELM Neuron\n",
    "\n",
    "This notebook demonstrates how to compute and analyze the Lyapunov spectrum for the ELM neuron model.\n",
    "\n",
    "The Lyapunov spectrum characterizes the dynamical properties of the system:\n",
    "- **Positive exponents**: Directions of exponential divergence (chaos)\n",
    "- **Zero exponents**: Marginal stability\n",
    "- **Negative exponents**: Directions of exponential convergence (stability)\n",
    "\n",
    "The maximum Lyapunov exponent indicates:\n",
    "- λ_max > 0: Chaotic dynamics\n",
    "- λ_max ≈ 0: Edge of chaos (critical dynamics)\n",
    "- λ_max < 0: Stable/periodic dynamics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "from pathlib import Path\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relative Imports\n",
    "package_path = Path(os.path.abspath(os.path.join(os.path.dirname('__file__'), '..')))\n",
    "sys.path.insert(0, str(package_path))\n",
    "\n",
    "from src.expressive_leaky_memory_neuron_v2 import ELM\n",
    "from src.lyapunov_spectrum import LyapunovSpectrumCalculator, analyze_lyapunov_spectrum\n",
    "from src.neuronio.neuronio_data_utils import (\n",
    "    NEURONIO_DATA_DIM, \n",
    "    NEURONIO_LABEL_DIM, \n",
    "    get_data_files_from_folder,\n",
    ")\n",
    "from src.neuronio.neuronio_data_loader import NeuronIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General Config\n",
    "general_config = dict()\n",
    "general_config[\"seed\"] = 0\n",
    "general_config[\"device\"] = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "general_config[\"model_dir\"] = \"../models/best_elm_neuron\"  # Change to desired model\n",
    "torch_device = torch.device(general_config[\"device\"])\n",
    "print(\"Torch Device: \", torch_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seeding & Determinism\n",
    "os.environ['PYTHONHASHSEED'] = str(general_config[\"seed\"])\n",
    "random.seed(general_config[\"seed\"])\n",
    "np.random.seed(general_config[\"seed\"])\n",
    "torch.manual_seed(general_config[\"seed\"])\n",
    "torch.cuda.manual_seed(general_config[\"seed\"])\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model config\n",
    "with open(general_config[\"model_dir\"] + \"/model_config.json\") as f:\n",
    "    model_config = json.load(f)\n",
    "\n",
    "# Load train config\n",
    "with open(general_config[\"model_dir\"] + \"/train_config.json\") as f:\n",
    "    train_config = json.load(f)\n",
    "\n",
    "print(\"Model config:\")\n",
    "print(f\"  num_memory: {model_config['num_memory']}\")\n",
    "print(f\"  num_branch: {model_config['num_branch']}\")\n",
    "print(f\"  num_input: {model_config['num_input']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and load the ELM model\n",
    "model = ELM(**model_config).to(torch_device)\n",
    "\n",
    "state_dict = torch.load(\n",
    "    general_config[\"model_dir\"] + \"/neuronio_best_model_state.pt\", \n",
    "    map_location=torch_device\n",
    ")\n",
    "print(model.load_state_dict(state_dict))\n",
    "model.eval()\n",
    "\n",
    "print(f\"\\nModel state dimension: {model.num_branch + model.num_memory}\")\n",
    "print(f\"  - Branch states: {model.num_branch}\")\n",
    "print(f\"  - Memory states: {model.num_memory}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data (Optional - for computing over dataset)\n",
    "\n",
    "You can either:\n",
    "1. Use real data from NeuronIO dataset\n",
    "2. Use synthetic random data for quick testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1: Load real data (requires downloaded NeuronIO dataset)\n",
    "USE_REAL_DATA = False  # Set to True if you have the dataset\n",
    "\n",
    "if USE_REAL_DATA:\n",
    "    data_dir_path = Path(\"~/Data\").expanduser().resolve()\n",
    "    test_data_dir_path = data_dir_path / \"neuronio_test_data\"\n",
    "    test_files = get_data_files_from_folder([str(test_data_dir_path)])\n",
    "    \n",
    "    # Create a small data loader for testing\n",
    "    test_data_loader = NeuronIO(\n",
    "        file_paths=test_files[:1],  # Use just one file for speed\n",
    "        batches_per_epoch=10,\n",
    "        batch_size=4,\n",
    "        input_window_size=train_config[\"input_window_size\"],\n",
    "        num_workers=2,\n",
    "        num_prefetch_batch=10,\n",
    "        file_load_fraction=0.1,\n",
    "        seed=general_config[\"seed\"],\n",
    "        device=torch_device,\n",
    "    )\n",
    "    print(\"Loaded real NeuronIO data\")\n",
    "else:\n",
    "    # Option 2: Use synthetic random data\n",
    "    print(\"Using synthetic random spike data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Lyapunov Spectrum\n",
    "\n",
    "### Parameters:\n",
    "- `num_transient`: Number of initial timesteps to discard (let system settle)\n",
    "- `num_iterations`: Number of timesteps used for computing the spectrum\n",
    "- `orthonormalize_every`: How often to perform QR decomposition (1 = every step, more accurate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Lyapunov calculator\n",
    "lyapunov_calc = LyapunovSpectrumCalculator(\n",
    "    model=model,\n",
    "    model_version=\"v2\",  # Use \"v1\" for old version, \"v2\" for new version\n",
    "    device=torch_device,\n",
    ")\n",
    "\n",
    "print(f\"State space dimension: {lyapunov_calc.state_dim}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick Test: Single Trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate or load a test input sequence\n",
    "if USE_REAL_DATA:\n",
    "    test_input, _ = next(iter(test_data_loader))\n",
    "else:\n",
    "    # Generate random spike input (sparse binary spikes)\n",
    "    batch_size = 2\n",
    "    seq_length = 3000  # Long enough for transient + computation\n",
    "    spike_prob = 0.05\n",
    "    test_input = (torch.rand(batch_size, seq_length, model_config['num_input']) < spike_prob).float()\n",
    "    test_input = test_input.to(torch_device)\n",
    "\n",
    "print(f\"Test input shape: {test_input.shape}\")\n",
    "print(f\"Spike rate: {test_input.mean().item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Lyapunov spectrum for a single trajectory\n",
    "result = lyapunov_calc.compute_spectrum(\n",
    "    inputs=test_input,\n",
    "    num_transient=500,        # Discard first 500 timesteps\n",
    "    num_iterations=2000,      # Use 2000 timesteps for computation\n",
    "    orthonormalize_every=1,   # QR decomposition every step (most accurate)\n",
    "    return_trajectory=False,  # Set to True to get state trajectory\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "print(f\"\\nComputed spectrum shape: {result['lyapunov_exponents'].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the results\n",
    "metrics = analyze_lyapunov_spectrum(result, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the Lyapunov spectrum\n",
    "spectrum_mean = np.mean(result['lyapunov_exponents'], axis=0)\n",
    "spectrum_sorted = np.sort(spectrum_mean)[::-1]\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Plot 1: Full spectrum\n",
    "axes[0].plot(spectrum_sorted, 'o-', markersize=3, linewidth=1)\n",
    "axes[0].axhline(y=0, color='r', linestyle='--', alpha=0.5, label='Zero line')\n",
    "axes[0].set_xlabel('Index (sorted)', fontsize=12)\n",
    "axes[0].set_ylabel('Lyapunov Exponent', fontsize=12)\n",
    "axes[0].set_title('Full Lyapunov Spectrum', fontsize=14, fontweight='bold')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "axes[0].legend()\n",
    "\n",
    "# Plot 2: Histogram\n",
    "axes[1].hist(spectrum_mean, bins=50, edgecolor='black', alpha=0.7)\n",
    "axes[1].axvline(x=0, color='r', linestyle='--', linewidth=2, label='Zero')\n",
    "axes[1].axvline(x=spectrum_mean.max(), color='g', linestyle='--', linewidth=2, \n",
    "                label=f'Max: {spectrum_mean.max():.4f}')\n",
    "axes[1].set_xlabel('Lyapunov Exponent', fontsize=12)\n",
    "axes[1].set_ylabel('Count', fontsize=12)\n",
    "axes[1].set_title('Distribution of Lyapunov Exponents', fontsize=14, fontweight='bold')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nTop 10 Lyapunov exponents:\")\n",
    "for i, val in enumerate(spectrum_sorted[:10]):\n",
    "    print(f\"  λ_{i+1}: {val:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced: Compute Across Multiple Trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute spectrum across multiple different input trajectories\n",
    "num_trajectories = 5\n",
    "all_spectra = []\n",
    "\n",
    "print(f\"Computing Lyapunov spectrum for {num_trajectories} different trajectories...\\n\")\n",
    "\n",
    "for i in range(num_trajectories):\n",
    "    if USE_REAL_DATA and i < len(test_data_loader):\n",
    "        test_input, _ = next(iter(test_data_loader))\n",
    "    else:\n",
    "        # Generate different random inputs\n",
    "        test_input = (torch.rand(2, 3000, model_config['num_input']) < spike_prob).float()\n",
    "        test_input = test_input.to(torch_device)\n",
    "    \n",
    "    result_i = lyapunov_calc.compute_spectrum(\n",
    "        inputs=test_input,\n",
    "        num_transient=500,\n",
    "        num_iterations=2000,\n",
    "        orthonormalize_every=1,\n",
    "        verbose=False,\n",
    "    )\n",
    "    all_spectra.append(result_i['lyapunov_exponents'])\n",
    "    print(f\"Trajectory {i+1}: max λ = {result_i['max_exponent'].mean():.6f}\")\n",
    "\n",
    "# Aggregate results\n",
    "all_spectra = np.concatenate(all_spectra, axis=0)\n",
    "mean_spectrum = np.mean(all_spectra, axis=0)\n",
    "std_spectrum = np.std(all_spectra, axis=0)\n",
    "\n",
    "print(f\"\\n{'-'*60}\")\n",
    "print(f\"Aggregate statistics over {num_trajectories} trajectories:\")\n",
    "print(f\"  Mean max λ: {np.max(mean_spectrum):.6f} ± {std_spectrum[np.argmax(mean_spectrum)]:.6f}\")\n",
    "print(f\"  Mean # positive: {np.mean(np.sum(all_spectra > 0, axis=1)):.1f}\")\n",
    "print(f\"{'-'*60}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot aggregate spectrum with error bars\n",
    "mean_sorted_idx = np.argsort(mean_spectrum)[::-1]\n",
    "mean_sorted = mean_spectrum[mean_sorted_idx]\n",
    "std_sorted = std_spectrum[mean_sorted_idx]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "ax.errorbar(range(len(mean_sorted)), mean_sorted, yerr=std_sorted, \n",
    "            fmt='o-', markersize=3, linewidth=1, capsize=2, alpha=0.7,\n",
    "            label='Mean ± Std')\n",
    "ax.axhline(y=0, color='r', linestyle='--', alpha=0.5, linewidth=2, label='Zero line')\n",
    "ax.fill_between(range(len(mean_sorted)), 0, mean_sorted, where=(mean_sorted > 0), \n",
    "                 alpha=0.3, color='red', label='Chaotic directions')\n",
    "ax.fill_between(range(len(mean_sorted)), 0, mean_sorted, where=(mean_sorted < 0), \n",
    "                 alpha=0.3, color='blue', label='Stable directions')\n",
    "ax.set_xlabel('Index (sorted)', fontsize=12)\n",
    "ax.set_ylabel('Lyapunov Exponent', fontsize=12)\n",
    "ax.set_title(f'Aggregate Lyapunov Spectrum ({num_trajectories} trajectories)', \n",
    "             fontsize=14, fontweight='bold')\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Different Models\n",
    "\n",
    "You can compare Lyapunov spectra across different model sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of models to compare\n",
    "model_dirs = [\n",
    "    \"../models/num_memory_10\",\n",
    "    \"../models/num_memory_20\",\n",
    "    \"../models/num_memory_50\",\n",
    "    \"../models/num_memory_100\",\n",
    "]\n",
    "\n",
    "comparison_results = {}\n",
    "\n",
    "for model_dir in model_dirs:\n",
    "    if not Path(model_dir).exists():\n",
    "        print(f\"Skipping {model_dir} (not found)\")\n",
    "        continue\n",
    "    \n",
    "    # Load model\n",
    "    with open(model_dir + \"/model_config.json\") as f:\n",
    "        config = json.load(f)\n",
    "    \n",
    "    model_comp = ELM(**config).to(torch_device)\n",
    "    state_dict = torch.load(model_dir + \"/neuronio_best_model_state.pt\", map_location=torch_device)\n",
    "    model_comp.load_state_dict(state_dict)\n",
    "    model_comp.eval()\n",
    "    \n",
    "    # Compute spectrum\n",
    "    calc = LyapunovSpectrumCalculator(model_comp, model_version=\"v2\", device=torch_device)\n",
    "    \n",
    "    # Use same input for fair comparison\n",
    "    test_input = (torch.rand(2, 3000, config['num_input']) < 0.05).float().to(torch_device)\n",
    "    \n",
    "    result = calc.compute_spectrum(\n",
    "        inputs=test_input,\n",
    "        num_transient=500,\n",
    "        num_iterations=2000,\n",
    "        orthonormalize_every=1,\n",
    "        verbose=False,\n",
    "    )\n",
    "    \n",
    "    model_name = f\"d_m={config['num_memory']}\"\n",
    "    comparison_results[model_name] = np.mean(result['lyapunov_exponents'], axis=0)\n",
    "    \n",
    "    print(f\"{model_name}: max λ = {np.max(comparison_results[model_name]):.6f}, \"\n",
    "          f\"# positive = {np.sum(comparison_results[model_name] > 0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot comparison\n",
    "if len(comparison_results) > 0:\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    \n",
    "    for name, spectrum in comparison_results.items():\n",
    "        sorted_spectrum = np.sort(spectrum)[::-1]\n",
    "        ax.plot(sorted_spectrum, 'o-', markersize=3, linewidth=1.5, label=name, alpha=0.7)\n",
    "    \n",
    "    ax.axhline(y=0, color='k', linestyle='--', alpha=0.3, linewidth=2)\n",
    "    ax.set_xlabel('Index (sorted)', fontsize=12)\n",
    "    ax.set_ylabel('Lyapunov Exponent', fontsize=12)\n",
    "    ax.set_title('Lyapunov Spectrum Comparison Across Model Sizes', fontsize=14, fontweight='bold')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results to file\n",
    "output_dir = Path(general_config[\"model_dir\"]) / \"lyapunov_analysis\"\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "np.savez(\n",
    "    output_dir / \"lyapunov_spectrum.npz\",\n",
    "    spectrum=mean_spectrum,\n",
    "    spectrum_std=std_spectrum,\n",
    "    all_spectra=all_spectra,\n",
    "    metrics=metrics,\n",
    ")\n",
    "\n",
    "print(f\"Results saved to {output_dir}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
